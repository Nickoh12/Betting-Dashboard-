{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "from datetime import date \n",
    "from datetime import datetime\n",
    "import pandas as pd \n",
    "import re \n",
    "import numpy as np\n",
    "import re\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support.expected_conditions import presence_of_element_located\n",
    "import sys\n",
    "import warnings\n",
    "from datetime import timedelta\n",
    "import time as timp \n",
    "import dateutil.parser\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "#Get df of leagues \n",
    "\n",
    "def get_pinn_leagues(URL):\n",
    "    chrome_path= r'C:\\Users\\Iris\\Documents\\Nico\\NicoUni\\Practicum\\Python\\Projects\\WebDrivers\\chromedriver.exe'\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    browser = webdriver.Chrome(\n",
    "        executable_path=chrome_path, options=chrome_options)\n",
    "    \n",
    "    browser.get(URL)\n",
    "    timp.sleep(20)\n",
    "\n",
    "    htmlSource = browser.page_source\n",
    "    \n",
    "    soup= BeautifulSoup(htmlSource, 'lxml')\n",
    "    league_name= []\n",
    "    links= []\n",
    "    for element in soup.find_all('a',{'class':'style_noLeftIcon__3p7DJ style_compact__1hNoP style_supportFavoritesList__20Xov'}):\n",
    "        links.append('https://www.pinnacle.com'+element['href'])\n",
    "        league_name.append(element.text)\n",
    "    \n",
    "    link_frame= pd.DataFrame({\n",
    "        'league': league_name,\n",
    "        'link': links})\n",
    "    \n",
    "    p= re.compile('.*[^0-9]')\n",
    "        \n",
    "    for i in np.arange(0,len(link_frame)):\n",
    "        link_frame['league'][i]= p.search(link_frame['league'][i]).group()\n",
    "        \n",
    "    return(link_frame)\n",
    "\n",
    "\n",
    "#def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(URL):\n",
    "    import time as timp\n",
    "    chrome_path= r'C:\\Users\\Iris\\Documents\\Nico\\NicoUni\\Practicum\\Python\\Projects\\WebDrivers\\chromedriver.exe'\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument('--headless')\n",
    "    browser = webdriver.Chrome(executable_path=chrome_path, options=chrome_options)\n",
    "    browser.get(URL)\n",
    "    timp.sleep(10)\n",
    "    soup= BeautifulSoup(browser.page_source, 'lxml')\n",
    "    df= pd.DataFrame()\n",
    "    error= []\n",
    "\n",
    "    df= pd.DataFrame()\n",
    "    \n",
    "    for element in soup.find_all('div',{'class':'style_dateBar__2PS4O'}):\n",
    "        count= len(element.text)\n",
    "        if  count < 6:\n",
    "            date= pd.to_datetime(datetime.now(), format=\"%d/%m/%Y\")\n",
    "        if 'Tomorrow' in element.text:\n",
    "            days_add= timedelta(days= 1)\n",
    "            date= pd.to_datetime(datetime.now(),format=\"%d/%m/%Y\")+days_add\n",
    "        else:\n",
    "            try:\n",
    "                temp_date= dateutil.parser.parse(element.text.split(',',1)[1][1:].replace(',',''))\n",
    "                date= pd.to_datetime(temp_date, format= '%d/%m/%Y')\n",
    "            except:\n",
    "                date= element.text\n",
    "        for tag in element.next_siblings:\n",
    "            if tag['class'] == ['style_dateBar__2PS4O']:\n",
    "                break\n",
    "            if tag['class']== ['style_row__3_aBC','style_lastRow__3h8Pm'] or tag['class']== ['style_row__3_aBC']:\n",
    "                try:\n",
    "                    teams= tag.find_all('span', {'class':'style_participantName__CNiJz ellipsis'})\n",
    "                    play_time= tag.find('span',{'class':'style_time__1_zpO ellipsis'})\n",
    "                    odds= tag.find_all('span',{'class':'price'})\n",
    "                    fest= pd.DataFrame({'date':date,\n",
    "                                    'scrape_time':pd.to_datetime(datetime.now(), format=\"%d/%m/%Y %H:%M\"),\n",
    "                                    'time':play_time.text,\n",
    "                         'home_team': teams[0].text,\n",
    "                         'away_team': teams[1].text,\n",
    "                         'PinnacleHome': odds[0].text,\n",
    "                         'PinnacleDraw': odds[1].text,\n",
    "                         'PinnacleAway': odds[2].text}, index= pd.Series(0))\n",
    "                    df= df.append(fest)\n",
    "                except:\n",
    "                    continue\n",
    "    return(df.reset_index(drop= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#get_results('https://www.pinnacle.com/en/soccer/egypt-premier-league/matchups')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I've got to \n",
    "1. Fix the dates !! Still Valid \n",
    "3. Make sure there is not a big time-lag--> Time lag must be a parameter to be optimised \n",
    "4. Prepare the data for the merge \n",
    "5. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Very Important script\n",
    "# links= get_pinn_leagues('https://www.pinnacle.com/en/soccer/leagues')\n",
    "\n",
    "results= pd.DataFrame()\n",
    "errors= []\n",
    "\n",
    "for i,element in enumerate(links['link'][0:1]):\n",
    "    try:\n",
    "        df= get_results(element)\n",
    "        df['league']= links['league'][i]\n",
    "        results= results.append(df)\n",
    "        \n",
    "    except:\n",
    "        errors.append(element) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
